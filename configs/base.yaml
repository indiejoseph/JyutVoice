# model config
gin_channels: 256
hidden_channels: 256
filter_channels: 1024
kernel_size: 3
n_heads: 4
p_dropout: 0.1

# mel config
sample_rate: 44100
n_fft: 2048
win_length: 2048
hop_length: 512
f_min: 0
f_max: null
pad: 0
n_mels: 128
center: false
pad_mode: "reflect"
mel_scale: "slaney"

tts: !new:jyutvoice.models.jyutvoice_tts.JyutVoiceTTS
  gin_channels: !ref <gin_channels>
  mel_channels: !ref <n_mels>
  encoder: !new:jyutvoice.models.text_encoder.TextEncoder
    n_vocab: 97
    n_lang: 4 # Pad + Cantonese, Mandarin, English
    n_tone: 7 # pad + 6 tones
    out_channels: !ref <n_mels>
    hidden_channels: !ref <hidden_channels>
    filter_channels: !ref <filter_channels>
    n_heads: !ref <n_heads>
    n_layers: 3
    kernel_size: !ref <kernel_size>
    p_dropout: !ref <p_dropout>
    gin_channels: !ref <gin_channels>

  ref_encoder: !new:jyutvoice.models.reference_encoder.MelStyleEncoder
    n_mel_channels: !ref <n_mels>
    style_hidden: 128
    style_vector_dim: !ref <gin_channels>
    style_kernel_size: 5
    style_head: 2
    dropout: 0.25

  dp: !new:jyutvoice.models.duration_predictor.DurationPredictor
    in_channels: !ref <hidden_channels>
    filter_channels: !ref <filter_channels>
    kernel_size: !ref <kernel_size>
    p_dropout: 0.5
    gin_channels: !ref <gin_channels>

  decoder: !new:jyutvoice.models.flow_matching.CFMDecoder
    noise_channels: !ref <n_mels>
    cond_channels: !ref <n_mels>
    hidden_channels: !ref <hidden_channels>
    out_channels: !ref <n_mels>
    filter_channels: !ref <filter_channels>
    n_heads: !ref <n_heads>
    n_layers: 6
    kernel_size: !ref <kernel_size>
    p_dropout: !ref <p_dropout>
    gin_channels: !ref <gin_channels>

  # pretrain_path: pretrained_models/pretrain.pt # Path to pretrained checkpoint for transfer learning
  optimizer: !name:torch.optim.AdamW
    lr: 5e-5
    weight_decay: 0.0
  scheduler: null
  warmup_steps: 300 # Number of warmup steps for learning rate

vocoder: !new:jyutvoice.vocoders.vocos.models.model.Vocos
  vocos_config: !new:jyutvoice.vocoders.vocos.config.VocosConfig
    input_channels: 128
    dim: 512
    intermediate_dim: 1536
    num_layers: 8
  mel_config: !new:jyutvoice.vocoders.vocos.config.MelConfig
    sample_rate: !ref <sample_rate>
    n_fft: !ref <n_fft>
    win_length: !ref <win_length>
    hop_length: !ref <hop_length>
    f_min: !ref <f_min>
    f_max: !ref <f_max>
    pad: !ref <pad>
    n_mels: !ref <n_mels>
    center: !ref <center>
    pad_mode: !ref <pad_mode>
    mel_scale: !ref <mel_scale>

mel_extractor: !new:jyutvoice.utils.audio.LogMelSpectrogram
  sample_rate: !ref <sample_rate>
  n_fft: !ref <n_fft>
  win_length: !ref <win_length>
  hop_length: !ref <hop_length>
  f_min: !ref <f_min>
  f_max: !ref <f_max>
  pad: !ref <pad>
  n_mels: !ref <n_mels>
  center: !ref <center>
  pad_mode: !ref <pad_mode>
  mel_scale: !ref <mel_scale>

data: !new:jyutvoice.data.text_mel_datamodule.TextMelDataModule
  name: jyutvoice_tts
  dataset_path: tmp/dummy_dataset_resaved
  batch_size: 32
  num_workers: 8
  pin_memory: true
  dataset_valid_ratio: 0.001
  seed: 42
  load_durations: false
  n_fft: !ref <n_fft>
  n_feats: !ref <n_mels>
  sample_rate: !ref <sample_rate>
  hop_length: !ref <hop_length>
  win_length: !ref <win_length>
  f_min: !ref <f_min>
  f_max: !ref <f_max>
  center: !ref <center>
  pad: !ref <pad>
  pad_mode: !ref <pad_mode>
  mel_scale: !ref <mel_scale>

trainer: !new:lightning.Trainer
  accelerator: auto
  devices: 1
  precision: bf16-mixed
  max_epochs: 2
  detect_anomaly: false # raise exception if NaN or +/-inf is detected in any tensor (disable for performance)
  log_every_n_steps: 10
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 0 # have to be 0 for testing
  gradient_clip_val: 3.0
  gradient_clip_algorithm: "norm"

callbacks:
  model_checkpoint:
    _target_: lightning.pytorch.callbacks.ModelCheckpoint
    dirpath: checkpoints
    filename: checkpoint_{epoch:03d}
    monitor: val_loss
    verbose: False
    save_last: true
    save_top_k: 10
    mode: "min"
    auto_insert_metric_name: True
    save_weights_only: False
    every_n_epochs: 1
    save_on_train_epoch_end: null

# Checkpoint Configuration

# WandB Logging Configuration
logger:
  # wandb:
  #   _target_: lightning.pytorch.loggers.wandb.WandbLogger
  #   name: jyutvoice-tts # Project name
  #   project: jyutvoice-tts # WandB project name
  #   entity: null # Set to your WandB team name if you have one
  #   log_model: false # Set to true to log model checkpoints
  #   prefix: ""
  #   notes: "JyutVoice TTS with StableTTS"
